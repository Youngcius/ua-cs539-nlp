{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spacy Tutorial for NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## NLP foundations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usual NLP tasks\n",
    "\n",
    "- tokenization：分词\n",
    "- \n",
    "- post-of-speech：词性标注\n",
    "- named entity recognition: 命名实体识别"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General pipeline in Spacy\n",
    "使用spaCy时，文本字符串的第一步是将其传递给NLP对象。这个对象本质上是由几个文本预处理操作组成的管道，输入文本字符串必须通过这些操作。\n",
    "\n",
    "![](https://img2020.cnblogs.com/other/1981858/202009/1981858-20200919132225169-1952649643.jpg)\n",
    "\n",
    "\n",
    "**Spacy 内统计模型**\n",
    "\n",
    "- `en_core_web_sm`：英语多任务CNN，在OntoNotes上训练，大小为11 MB\n",
    "\n",
    "- `en_core_web_md`：英语多任务CNN，在OntoNotes上训练，并且使用Common Crawl上训练的GLoVe词嵌入，大小为91 MB\n",
    "\n",
    "- `en_core_web_lg`：英语多任务CNN，在OntoNotes上训练，并且使用Common Crawl上训练的GLoVe词嵌入，大小为789 MB\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**相应的组件 in Spacy**：\n",
    "\n",
    "- 标记生成器\n",
    "- 标签器\n",
    "- 生成器\n",
    "- 解析器\n",
    "- NER\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example**\n",
    "\n",
    "1. 导入统计模型，创建 NLP 对象"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tagger', 'parser', 'ner']\n",
      "['tagger', 'parser', 'ner']\n",
      "['tagger', 'parser', 'ner']\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "sm_nlp = spacy.load('en_core_web_sm')\n",
    "md_nlp = spacy.load('en_core_web_md')\n",
    "lg_nlp = spacy.load('en_core_web_lg')\n",
    "\n",
    "print(sm_nlp.pipe_names)\n",
    "print(md_nlp.pipe_names)\n",
    "print(lg_nlp.pipe_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 基本的分词操作、数据类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "document object 长度： 13\n",
      "<class 'spacy.tokens.token.Token'> \t [Dr., Jennifer, Smith, visited, China, ., She, liked, the, country, a, lot, .]\n",
      "Dr. Jennifer Smith visited China. She liked the country a lot.\n",
      "<class 'spacy.tokens.doc.Doc'>\n"
     ]
    }
   ],
   "source": [
    "string = 'Dr. Jennifer Smith visited China. She liked the country a lot.'\n",
    "doc = md_nlp(string)\n",
    "print('document object 长度：', len(doc))\n",
    "print(type(doc[0]),'\\t', [t for t in doc])\n",
    "print(doc)\n",
    "print(type(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.token.Token"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(doc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'generator'>\n",
      "<class 'spacy.tokens.span.Span'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Dr. Jennifer Smith visited China.', 'She liked the country a lot.']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sentences\n",
    "print(type(doc.sents))\n",
    "print(type(next(doc.sents)))\n",
    "[sent.text for sent in doc.sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.token.Token"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokens\n",
    "sents = list(doc.sents) # convert `generator` to `list` type\n",
    "tokens = sents[0] # 第一个句子中的 tokens\n",
    "type(tokens[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Dr.', 'Dr.'],\n",
       " ['Jennifer', 'Jennifer'],\n",
       " ['Smith', 'Smith'],\n",
       " ['visited', 'visit'],\n",
       " ['China', 'China'],\n",
       " ['.', '.']]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_lemma = [[token.text, token.lemma_] for token in tokens]\n",
    "token_lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([[token.text for token in sent] for sent in doc.sents])\n",
    "# Print a table of tokens and their lemmas\n",
    "print(table([[token.text, token.lemma_] for token in doc]))\n",
    "\n",
    "# Print sample embedding vectors\n",
    "visited = doc[3]\n",
    "china = doc[5]\n",
    "country = doc[10]\n",
    "\n",
    "print(visited.vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 词嵌入向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300,)\n",
      "(300,)\n"
     ]
    }
   ],
   "source": [
    "print(doc.vector.shape)\n",
    "print(doc[0].vector.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similarity(china, visited): 0.16252194\n",
      "similarity(china, country): 0.29160026\n",
      "similarity(china, India): 0.20743968\n"
     ]
    }
   ],
   "source": [
    "# Print sample embedding vectors\n",
    "visited = doc[3]\n",
    "china = doc[5]\n",
    "country = doc[10]\n",
    "\n",
    "sim = china.similarity\n",
    "print(\"similarity(china, visited): \" + str(sim(visited)))\n",
    "print(\"similarity(china, country): \" + str(sim(country)))\n",
    "print(\"similarity(china, India): \" + str(sim(md_nlp(\"India\")[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. 命名实体 & 标签\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Jennifer Smith', 'PERSON'), ('China', 'GPE')]\n",
      "<class 'tuple'> <class 'spacy.tokens.span.Span'>\n"
     ]
    }
   ],
   "source": [
    "print([(ent.text, ent.label_) for ent in doc.ents]) # 每一个 ent 是一个 Span 数据类型，包含一个或多个 token\n",
    "print(type(doc.ents), type(doc.ents[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. little summary\n",
    "   - 首先创建 nlp 模型: `nlp = spacy.load(<model name>)`\n",
    "   - 生成 NLP 对象：`doc = nlp(<str obj>)` 生成的是 `spacy.tokens.Doc` 类型的对象；`doc` 可索引，`doc[i]` 是 `spacy.tokens.Token` 类型；`doc` 长度为得到的分词个数\n",
    "   - Sentences：`doc.sents` 是对众多 tokens 的组装，是为 python 生成器，每一个元素是 `spacy.tokens.Span` 类型\n",
    "   - Entities：`doc.ents` 是 python 元组，每一个元素是 `spacy.tokens.Span` 类型，因为 entity 由一个或多个 token 组成，元素的 `.label_` 属性表示实体标签\n",
    "   - Other：词性标注使用 `token.pos_` 属性，单词原形使用 `token.lemma_`，语法依存分析使用 `token.dep_`，"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'auxiliary'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain('AUX')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference\n",
    "\n",
    "- [Spacy 学习教程](https://www.cnblogs.com/panchuangai/p/13695902.html)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b77a81e5f1b2e8569f76c609cf8e4767cf030d92fee033b4f5ddd64efbe98908"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
